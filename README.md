# Decifrando a Caixa Preta: LIME aplicado ao German Credit (Statlog)

## Resumo executivo
Este projeto demonstra como gerar **explica√ß√µes locais** para decis√µes de um modelo de cr√©dito usando **LIME** (Local Interpretable Model-agnostic Explanations). O objetivo √© fornecer transpar√™ncia em decis√µes autom√°ticas ‚Äî especialmente nega√ß√µes de cr√©dito ‚Äî para clientes, gestores e √≥rg√£os regulat√≥rios.

O dataset utilizado √© o **Statlog (German Credit)** (UCI) ‚Äî 1.000 amostras com ~20 atributos que descrevem informa√ß√µes sociodemogr√°ficas e financeiras dos solicitantes.

---

## Estrutura do reposit√≥rio
- `Projeto_XAI_LIME_GermanCredit.py` ‚Äî script principal (treino do modelo, avalia√ß√£o, gera√ß√£o de explica√ß√µes LIME e salvamento de outputs).
- `tune_and_compare.py` ‚Äî script para busca de hiperpar√¢metros e compara√ß√£o entre modelos (RandomForest, HistGradientBoosting, LogisticRegression).
- `notebook_for_video.ipynb` ‚Äî notebook indicado para apresenta√ß√£o e grava√ß√£o do v√≠deo (cont√©m c√©lulas prontas).
- `requirements.txt` ‚Äî depend√™ncias do projeto.
- `outputs/` ‚Äî diret√≥rio onde s√£o salvas matrizes de confus√£o, relat√≥rios, imagens e arquivos HTML com explica√ß√µes do LIME.

---

## Objetivos do trabalho
1. Treinar um classificador para prever risco de cr√©dito (bom vs mau).
2. Gerar **explica√ß√µes locais** (com LIME) que mostrem quais features influenciaram cada previs√£o.
3. Interpretar e discutir as explica√ß√µes, ressaltando uso pr√°tico e limita√ß√µes.
4. Preparar material (c√≥digo, README e roteiro) para apresenta√ß√£o (v√≠deo de at√© 4 minutos).

---

## Abordagem t√©cnica (resumo)
1. **Pr√©-processamento**
   - Separar colunas num√©ricas e categ√≥ricas.
   - Aplicar `OneHotEncoder` para vari√°veis categ√≥ricas (handle_unknown='ignore').
   - Pipeline do scikit-learn com `ColumnTransformer` para garantir reprodutibilidade.
2. **Modelagem**
   - Modelo principal: `RandomForestClassifier` (boa baseline para dados tabulares).
   - Alternativas testadas no `tune_and_compare.py`: `HistGradientBoostingClassifier` e `LogisticRegression`.
   - Valida√ß√£o: `train_test_split` estratificado e m√©tricas como accuracy, precision, recall, f1-score e matriz de confus√£o.
3. **Interpretabilidade**
   - `lime.lime_tabular.LimeTabularExplainer`: explica decis√µes **localmente** ao gerar um modelo linear sobre uma vizinhan√ßa sintetizada da inst√¢ncia.
   - Gerar explica√ß√µes para casos espec√≠ficos (ex.: cliente negado) e salvar HTML/PNG para apresenta√ß√£o.
4. **Entrega**
   - Salvamos explica√ß√µes como HTML (visual interativo) e imagens PNG para inclus√£o no relat√≥rio/v√≠deo.

---

## Exemplo de uso (resumo r√°pido)
1. Criar ambiente virtual e instalar depend√™ncias:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```
2. Baixar dataset `german.data` (UCI Statlog) e coloc√°-lo na raiz do projeto (ou usar a fun√ß√£o `download_dataset()` presente no notebook/script).
3. Executar:
```bash
python Projeto_XAI_LIME_GermanCredit.py
```
4. Verificar `outputs/` (classification_report, confusion_matrix.png, lime_explanation_idxX.html, etc).

---

## Interpreta√ß√£o pr√°tica das explica√ß√µes (como usar com stakeholders)
- **Para um cliente:** mostrar as 3‚Äì5 features que mais influenciaram a decis√£o e traduzir tecnicamente (ex.: "hist√≥rico de cr√©dito: ruim" => alto peso para negar).
- **Para compliance:** manter registro das explica√ß√µes por decis√£o, demonstrando que cada nega√ß√£o foi baseada em vari√°veis mensur√°veis.
- **Para time de produto/neg√≥cios:** agregar explica√ß√µes (contar features recorrentes) para detectar vieses ou problemas de dados.

---

## Limita√ß√µes e cuidados
- **Localidade:** LIME explica uma vizinhan√ßa local ‚Äî explica√ß√µes n√£o garantem comportamento global do modelo.
- **Instabilidade:** pequenas mudan√ßas no seed, no pr√©-processamento ou nas amostras sint√©ticas podem alterar explica√ß√µes.
- **Correla√ß√µes entre features:** LIME assume independ√™ncia local ao perturbar features; se h√° fortes correla√ß√µes, as explica√ß√µes podem ser enganosas.
- **Dados sens√≠veis:** certifique-se de n√£o usar features legalmente protegidas na decis√£o sem controle (ex.: g√™nero/ra√ßa), e registre justificativas de uso.
- **Auditoria:** use LIME como parte de um processo maior (logs, avalia√ß√µes globais como SHAP, fairness checks, testes com contrafactuals).

---

## Sugest√µes de melhorias futuras
- Comparar LIME com SHAP (explica√ß√£o local vs. explica√ß√£o baseada em valores SHAP).
- Implementar an√°lise global: feature importance, partial dependence plots e an√°lise de equidade (fairness).
- Pipeline de monitoramento de explica√ß√µes em produ√ß√£o (salvar explica√ß√£o por transa√ß√£o, monitorar drift).
- Testes de estabilidade: rodar LIME m√∫ltiplas vezes e medir vari√¢ncia nas import√¢ncias.

---

## Refer√™ncias
- Ribeiro, M.T., Singh, S., & Guestrin, C. (2016). *"Why Should I Trust You? Explaining the Predictions of Any Classifier"*. arXiv:1602.04938.
- LIME documentation: https://marcotcr.github.io/lime/tutorials.html
- UCI Machine Learning Repository ‚Äî Statlog (German Credit Data): https://archive.ics.uci.edu/
- Blog: *Explainable AI with LIME and SHAP* (Towards Data Science)

---




## üìä Estrutura do Projeto

O reposit√≥rio foi organizado da seguinte forma:

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ german_credit_data.csv       # Dataset original
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ lime_example_1.png           # Exemplo de explica√ß√£o LIME
‚îÇ   ‚îú‚îÄ‚îÄ lime_example_2.png           # Outro exemplo visual
‚îú‚îÄ‚îÄ Projeto_XAI_LIME_Notebook.ipynb  # Notebook principal com c√≥digo e an√°lise
‚îú‚îÄ‚îÄ requirements.txt                 # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                        # Documenta√ß√£o do projeto
```

---

## üõ†Ô∏è Passo a Passo do Projeto

1. **Coleta de Dados**  
   Utilizamos o dataset Statlog (German Credit Data) disponibilizado pela UCI Machine Learning Repository.

2. **Pr√©-processamento**  
   - Tratamento de valores nulos (quando necess√°rio)
   - Codifica√ß√£o de vari√°veis categ√≥ricas com *OneHotEncoder*
   - Normaliza√ß√£o de atributos num√©ricos

3. **Treinamento do Modelo**  
   Foi utilizada uma **Random Forest Classifier** para prever se um cliente √© "bom" ou "mau" pagador.

4. **Aplica√ß√£o do LIME**  
   - Escolha de inst√¢ncias individuais para explicar
   - Gera√ß√£o de explica√ß√µes locais
   - Visualiza√ß√£o dos pesos atribu√≠dos a cada feature

5. **An√°lise dos Resultados**  
   - Interpreta√ß√£o das features mais relevantes
   - Compara√ß√£o entre diferentes previs√µes
   - Discuss√£o de limita√ß√µes

---

## üìå Exemplo de Sa√≠da do LIME

Abaixo, um exemplo fict√≠cio de explica√ß√£o LIME:

![Exemplo LIME](images/lime_example_1.png)

**Interpreta√ß√£o:**  
- **Idade > 40 anos** ‚Üí aumentou a probabilidade de bom cr√©dito (+0.18)  
- **Hist√≥rico de inadimpl√™ncia recente** ‚Üí reduziu a probabilidade (-0.25)  
- **Renda acima da m√©dia** ‚Üí impacto positivo (+0.12)

---

## ‚ö†Ô∏è Limita√ß√µes do Estudo

- O LIME fornece explica√ß√µes **locais**, ou seja, v√°lidas apenas para a inst√¢ncia analisada.  
- A escolha do n√∫mero de features exibidas pode afetar a interpreta√ß√£o.  
- Modelos muito complexos podem gerar explica√ß√µes menos consistentes.

---

## üìö Refer√™ncias

- Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). *"Why Should I Trust You?": Explaining the Predictions of Any Classifier*. arXiv preprint arXiv:1602.04938.  
- Documenta√ß√£o oficial do LIME: https://marcotcr.github.io/lime/tutorials.html  
- Dataset: UCI Machine Learning Repository - Statlog (German Credit Data)  
- Blog *Towards Data Science*: https://towardsdatascience.com/explainable-ai-with-lime-shap-7e8d3bfaac8e

---

## ‚úÖ Conclus√£o

Este projeto demonstrou como √© poss√≠vel combinar **modelos preditivos de Machine Learning** com **t√©cnicas de interpretabilidade** para oferecer explica√ß√µes claras e √∫teis sobre decis√µes algor√≠tmicas.  
O uso do LIME permitiu identificar quais vari√°veis tiveram maior impacto em cada decis√£o, oferecendo **transpar√™ncia** e **confian√ßa** tanto para usu√°rios quanto para √≥rg√£os regulat√≥rios.

A aplica√ß√£o pr√°tica desse tipo de abordagem √© fundamental em setores como:
- **Bancos e Finan√ßas** (cr√©dito e empr√©stimos)
- **Sa√∫de** (diagn√≥stico assistido por IA)
- **Seguros** (avalia√ß√£o de risco)

Com isso, refor√ßamos que a **IA explic√°vel** √© um passo essencial para ado√ß√£o segura e respons√°vel de algoritmos na sociedade.
